{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Inesdata-AI-Services","text":"<p><code>Inesdata-AI-Services</code> es la plataforma de desarrollo de Inteligencia Artificial basada en Kubeflow</p> <p>Dicha plataforma est\u00e1 instalada sobre un cluster de Kubernetes con las siguientes caracter\u00edsticas:</p> <p> Master (x3) Worker (x10) LEN (x2) CPU 8 32 48 RAM (GB) 16 64 192 GPU (GB) - - 3 x 40  2 x 20 <p></p> <p>Para el correcto uso de la platforma, se han desarrollado las siguientes gu\u00edas:</p> <ul> <li> <p>\ud83d\udee0\ufe0f Gu\u00edas de instalaci\u00f3n y administraci\u00f3n. Se detalla el proceso de los distintos componentes as\u00ed como la configuraci\u00f3n concreta de los mismos. Tambi\u00e9n detalla c\u00f3mo gestionar el acceso y alta/baja de usuarios.</p> </li> <li> <p>\ud83d\udcda Gu\u00eda de usuario. Indica c\u00f3mo usar las funcionalidades de la plataforma desde un punto de vista de usuario</p> </li> </ul>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#110-20241001","title":"1.1.0 2024/10/01","text":"<ul> <li>Migraci\u00f3n a nuevo cl\u00faster. Se consigue un aumento de rendimiento general de la plataforma.</li> <li>Acutalizaci\u00f3n de URL de acceso a la plataforma.</li> <li>Actualizaci\u00f3n de URL de administraci\u00f3n de la plataforma.</li> <li>Se actualiza la <code>Kserve</code> a la versi\u00f3n <code>0.13.0</code>.</li> </ul>"},{"location":"changelog/#100-20240603","title":"1.0.0 2024/06/03","text":"<ul> <li>Versi\u00f3n inicial</li> </ul>"},{"location":"guias/administracion/","title":"Uso del script de administraci\u00f3n de usuarios","text":""},{"location":"guias/administracion/#descripcion-general","title":"Descripci\u00f3n general","text":"<p>Con el objetivo de simplificar el proceso de administrar usuarios (dar de alta, asignar recursos de computo, etc.), se ha desarrollado un script en <code>bash</code> que permite </p>"},{"location":"guias/administracion/#uso","title":"Uso","text":"<p>Desde la carpeta <code>kubeflow</code>, lanzar el siguiente comando: <pre><code>./kubeflow-admin.sh\n</code></pre> En pantalla se mostrar\u00e1 el men\u00fa principal: <pre><code>KUBEFLOW ADMIN:\n1) Create user\n2) Import user list\n3) Delete user\n4) Delete user list\n5) List users\n6) View user resources\n7) Modify user resources\n8) Exit\nType an option: \n</code></pre></p>"},{"location":"guias/administracion/#crear-usuario","title":"Crear usuario","text":"<p>Previamente debe existir el fichero <code>kubeflow/common/user-namespace/base/params.env</code> con la informaci\u00f3n correspondiente al perfil que se quiere crear.</p> <p>Ejecutar <code>kubeflow-admin.sh</code> y seleccionar la opci\u00f3n <code>1</code>.</p> <p>Seguidamente, aparecer\u00e1 una pantalla de confirmaci\u00f3n con los datos del perfil y solicitar\u00e1 confirmaci\u00f3n para proceder a crear el usuario en <code>Kubeflow</code> y <code>Keycloak</code>.</p>"},{"location":"guias/administracion/#importar-usuarios-desde-csv","title":"Importar usuarios desde CSV","text":"<p>Es necesario crear <code>common/user-namespace/base/import_users.csv</code> con el siguiente formato antes de continuar con el proceso: <pre><code>user,profile-name,kc-pass,cpu,memory,gpu,mig-gpu-20g,storage\nuser0@company.com,user0,pass0,8,16Gi,0,0,100Gi\nuser1@company.com,user1,pass1,4,32Gi,1,0,50Gi\n</code></pre></p> <p>Warning</p> <p>Dejar una linea en blanco al final del fichero.</p> <p>Note</p> <p><code>kc-pass</code> ser\u00e1 la contrase\u00f1a de acceso a <code>Kubeflow</code> que se crear\u00e1 al darse de alta en <code>Keycloak</code>.</p> <p>Seguidamente ejecutar <code>kubeflow-admin.sh</code> y seleccionar la opci\u00f3n <code>2</code>.</p> <p>Aparecer\u00e1 una pantalla de confirmaci\u00f3n antes de comenzar la importaci\u00f3n.</p>"},{"location":"guias/administracion/#listar-usuarios","title":"Listar usuarios","text":"<p>Ejecutar <code>kubeflow-admin.sh</code> y seleccionar la opci\u00f3n <code>5</code>.</p> <p>El script mostrar\u00e1 una lista con los usuarios dados de alta en <code>Kubeflow</code>.</p>"},{"location":"guias/administracion/#eliminar-usuario","title":"Eliminar usuario","text":"<p>Ejecutar <code>kubeflow-admin.sh</code> y seleccionar la opci\u00f3n <code>3</code>.</p> <p>Escribir por teclado el nombre del perfil que se desea elinminar.</p> <p>Aparecer\u00e1 una pantalla de confirmaci\u00f3n. Tras verificar la acci\u00f3n se procedera a eliminar el usuario de <code>Kubeflow</code> y <code>Keycloak</code>.</p>"},{"location":"guias/administracion/#eliminar-una-lista-de-usuarios","title":"Eliminar una lista de usuarios","text":"<p>Ejecutar <code>kubeflow-admin.sh</code> y seleccionar la opci\u00f3n <code>4</code>.</p> <p>Es necesario crear <code>common/user-namespace/base/delete_users.csv</code> con el siguiente formato antes de continuar con el proceso: <pre><code>profile-name\nuser0\nuser1\n</code></pre></p> <p>Warning</p> <p>Dejar una linea en blanco al final del fichero</p> <p>Aparecer\u00e1 una pantalla de confirmaci\u00f3n. Tras verificar la acci\u00f3n se proceder\u00e1 a eliminar los usuarios de <code>Kubeflow</code> y <code>Keycloak</code>.</p>"},{"location":"guias/administracion/#ver-recursos-de-usuario","title":"Ver recursos de usuario","text":"<p>Ejecutar <code>kubeflow-admin.sh</code> y seleccionar la opci\u00f3n <code>6</code>.</p> <p>Escribir por teclado el nombre del perfil que se desea consultar.</p> <p>El script mostrar\u00e1 una lista con los recursos disponibles para el usuario solicitado en <code>Kubeflow</code>.</p>"},{"location":"guias/administracion/#modicar-recursos-de-usuario","title":"Modicar recursos de usuario","text":"<p>Ejecutar <code>kubeflow-admin.sh</code> y seleccionar la opci\u00f3n <code>7</code>.</p> <p>Escribir por teclado el nombre del perfil que se desea modificar.</p> <p>En pantalla se mostrar\u00e1 el siguiente men\u00fa: <pre><code>KUBEFLOW ADMIN:\nEnter the profile name to modify: admin\n1) CPU\n2) Memory\n3) GPU\n4) Storage\n5) Cancel\nType the resource to modify on admin profile: \n</code></pre> Seguidamente seleccionar la opci\u00f3n del recurso a modificar y seleccionar el valor deseado para ser aplicado.</p>"},{"location":"guias/administracion/#salir-del-administrador-de-kubeflow","title":"Salir del administrador de Kubeflow","text":"<p>Ejecutar <code>kubeflow-admin.sh</code> y seleccionar la opci\u00f3n <code>8</code>.</p>"},{"location":"guias/instalacion/","title":"Gu\u00eda de instalaci\u00f3n","text":""},{"location":"guias/instalacion/#descripcion-general","title":"Descripci\u00f3n general","text":"<p>Esta gu\u00eda describe el proceso de instalaci\u00f3n de los Manifiestos de Kubeflow sobre los que se basa la plataforma <code>Inesdata-AI-Services</code>. Est\u00e1 basada en el repositorio de Manifiestos de Kubeflow. Dicho repositorio es propiedad del Grupo de Trabajo de Manifiestos.</p> <p>El repositorio est\u00e1 organizado en tres (3) directorios principales, que incluyen manifiestos para instalar:</p> Directorio Prop\u00f3sito <code>apps</code> Componentes oficiales de Kubeflow, mantenidos por los respectivos Grupos de Trabajo de Kubeflow <code>common</code> Servicios comunes, mantenidos por el Grupo de Trabajo de Manifiestos <code>contrib</code> Aplicaciones contribuidas por terceros, que se mantienen externamente y no forman parte de un Grupo de Trabajo de Kubeflow"},{"location":"guias/instalacion/#versiones-de-componentes-de-kubeflow","title":"Versiones de componentes de Kubeflow","text":""},{"location":"guias/instalacion/#version-de-kubeflow-180","title":"Versi\u00f3n de Kubeflow: 1.8.0","text":"<p>La siguiente matriz muestra la versi\u00f3n de git que se incluye para cada componente:</p> Componente Ruta de Manifiestos Locales Revisi\u00f3n Upstream Notebook Controller apps/jupyter/notebook-controller/upstream v1.8.0 PVC Viewer Controller apps/pvcviewer-roller/upstream v1.8.0 Central Dashboard apps/centraldashboard/upstream v1.8.0 Profiles + KFAM apps/profiles/upstream v1.8.0 PodDefaults Webhook apps/admission-webhook/upstream v1.8.0 Jupyter Web App apps/jupyter/jupyter-web-app/upstream v1.8.0 Volumes Web App apps/volumes-web-app/upstream v1.8.0 KServe contrib/kserve/kserve v0.13.0 KServe Models Web App contrib/kserve/models-web-app v0.13.0-rc.0 Kubeflow Pipelines apps/pipeline/upstream 2.0.3 <p>La siguiente es tambi\u00e9n una matriz con versiones de componentes comunes que son utilizados por los diferentes proyectos de Kubeflow:</p> Componente Ruta de Manifiestos Locales Revisi\u00f3n Upstream Istio common/istio 1.17.5 Knative common/knative/knative-serving  common/knative/knative-eventing 1.10.2 1.10.1 Cert Manager common/cert-manager 1.12.2"},{"location":"guias/instalacion/#instalacion","title":"Instalaci\u00f3n","text":"<p>Se realizar\u00e1 desplegando los paquetes por separado, verficando que se estan instalando satisfactoriamente antes de proseguir con el siguiente.</p> <p>Warning</p> <p>Se utiliza un correo electr\u00f3nico predeterminado (<code>example@gmv.com</code>) y una contrase\u00f1a (<code>-</code>). Para cualquier despliegue de Kubeflow en producci\u00f3n, se deber\u00e1 cambiar la identificaci\u00f3n predeterminada siguiendo la secci\u00f3n correspondiente.</p>"},{"location":"guias/instalacion/#prerrequisitos","title":"Prerrequisitos","text":"<ul> <li><code>Kubernetes</code> (hasta <code>1.29.3</code>) con una StorageClass predeterminada</li> <li><code>kustomize</code> 5.0.3<ul> <li> Kubeflow no es compatible con versiones anteriores de Kustomize. Esto se debe a que necesita el campo <code>sortOptions</code>, que solo est\u00e1 disponible en Kustomize 5 y posteriores #2388.</li> </ul> </li> <li><code>kubectl</code></li> </ul> <p>Note</p> <p>Los comandos <code>kubectl apply</code> pueden fallar en el primer intento. Esto es inherente a c\u00f3mo funcionan Kubernetes y <code>kubectl</code> (por ejemplo, CR debe crearse despu\u00e9s de que CRD est\u00e9 listo). La soluci\u00f3n es simplemente volver a ejecutar el comando hasta que tenga \u00e9xito. </p>"},{"location":"guias/instalacion/#instalar-componentes","title":"Instalar componentes","text":"<p>En esta secci\u00f3n, se procede a instalar cada componente oficial de Kubeflow (bajo <code>apps</code>) y cada servicio com\u00fan (bajo <code>common</code>) por separado, usando solo <code>kubectl</code> y <code>kustomize</code>.</p> <p>El prop\u00f3sito de esta secci\u00f3n es proporcionar una descripci\u00f3n de cada componente y una idea de c\u00f3mo se instala.</p> <p>Nota de resoluci\u00f3n de problemas</p> <p>Se han observado errores como el siguiente al aplicar las kustomizaciones de diferentes componentes: <pre><code>error: resource mapping not found for name: \"&lt;RESOURCE_NAME&gt;\" namespace: \"&lt;SOME_NAMESPACE&gt;\" from \"STDIN\": no matches for kind \"&lt;CRD_NAME&gt;\" in version \"&lt;CRD_FULL_NAME&gt;\"\nensure CRDs are installed first\n</code></pre></p> <p>Esto se debe a que una kustomizaci\u00f3n aplica tanto un CRD como un CR muy r\u00e1pidamente, y el CRD no ha alcanzado el estado de <code>Established</code> a\u00fan. Puede aprender m\u00e1s sobre esto en este issue de kubectl y en este issue de Helm.</p> <p>Si se muestra este error, se recomienda volver a aplicar la kustomizaci\u00f3n del componente.</p>"},{"location":"guias/instalacion/#antes-de-comenzar","title":"Antes de comenzar","text":"<p>Warning</p> <p>Se recomienda encarecidamente revisar el estado de los pods tras la instalaci\u00f3n de cada paquete, asegurandose que todos estan en estado <code>Ready</code> antes de continuar con el resto de la instalaci\u00f3n. As\u00ed en caso de error, ser\u00e1 mas sencillo identificar el problema y aplicar la soluci\u00f3n correspondiente.</p>"},{"location":"guias/instalacion/#cert-manager","title":"Cert-Manager","text":"<p>Cert-Manager es utilizado por muchos componentes de Kubeflow para proporcionar certificados para webhooks de admisi\u00f3n.</p> <p>Instalar Cert-Manager:</p> <pre><code>kubectl apply -k common/cert-manager/cert-manager/base\nkubectl wait --for=condition=ready pod -l 'app in (cert-manager,webhook)' --timeout=180s -n cert-manager\nkubectl apply -k common/cert-manager/kubeflow-issuer/base\n</code></pre> <p>En caso de que recibas este error: <pre><code>Error from server (InternalError): error when creating \"STDIN\": Internal error occurred: failed calling webhook \"webhook.cert-manager.io\": failed to call webhook: Post \"https://cert-manager-webhook.cert-manager.svc:443/mutate?timeout=10s\": dial tcp 10.96.202.64:443: connect: connection refused\n</code></pre> Esto es porque el webhook a\u00fan no est\u00e1 listo para recibir solicitudes. Espera unos segundos y vuelve a intentar aplicar los manifiestos.</p> <p>Para m\u00e1s informaci\u00f3n sobre resoluci\u00f3n de problemas, consulta la documentaci\u00f3n de Cert-Manager.</p> <p>Verificaci\u00f3n de instalaci\u00f3n correcta:</p> <pre><code>kubectl get pods -n cert-manager\n</code></pre>"},{"location":"guias/instalacion/#istio","title":"Istio","text":"<p>Istio es utilizado por muchos componentes de Kubeflow para asegurar su tr\u00e1fico, hacer cumplir la autorizaci\u00f3n de red y aplicar pol\u00edticas de enrutamiento.</p> <p>Instalar Istio:</p> <pre><code>kubectl apply -k common/istio/istio-crds/base\nkubectl apply -k common/istio/istio-namespace/base\nkubectl apply -k common/istio/istio-install/base\n</code></pre> <p>Verificaci\u00f3n de instalaci\u00f3n correcta:</p> <pre><code>kubectl get pods -n istio-system\n</code></pre>"},{"location":"guias/instalacion/#knative","title":"Knative","text":"<p>Knative es utilizado por el componente oficial de Kubeflow, KServe.</p> <p>Instalar Knative Serving:</p> <pre><code>kubectl apply -k common/knative/knative-serving/overlays/gateways\nkubectl apply -k common/istio/cluster-local-gateway/base\n</code></pre>"},{"location":"guias/instalacion/#namespace-de-kubeflow","title":"Namespace de Kubeflow","text":"<p>Crea el namespace donde vivir\u00e1n los componentes de Kubeflow. Este namespace se llama <code>kubeflow</code>.</p> <p>Instalar el namespace de kubeflow:</p> <pre><code>kubectl apply -k common/kubeflow-namespace/base\n</code></pre>"},{"location":"guias/instalacion/#kubeflow-roles","title":"Kubeflow Roles","text":"<p>Crea los ClusterRoles de Kubeflow, <code>kubeflow-view</code>, <code>kubeflow-edit</code> y <code>kubeflow-admin</code>. Los componentes de Kubeflow agregan permisos a estos ClusterRoles.</p> <p>Instalar los roles de kubeflow:</p> <pre><code>kubectl apply -k common/kubeflow-roles/base\n</code></pre>"},{"location":"guias/instalacion/#recursos-de-istio-para-kubeflow","title":"Recursos de Istio para Kubeflow","text":"<p>Crea los recursos de Istio necesarios para Kubeflow. Esta kustomizaci\u00f3n actualmente crea un Istio Gateway llamado <code>kubeflow-gateway</code>, en el namespace <code>kubeflow</code>. Si deseas instalar con tu propio Istio, tambi\u00e9n necesitar\u00e1s esta kustomizaci\u00f3n.</p> <p>Instalar recursos de istio:</p> <pre><code>kubectl apply -k common/istio/kubeflow-istio-resources/base\n</code></pre>"},{"location":"guias/instalacion/#kubeflow-pipelines","title":"Kubeflow Pipelines","text":"<p>Instalar los Multi-User Kubeflow Pipelines como componente oficial de Kubeflow:</p> <p><pre><code>kubectl apply -k apps/pipeline/upstream/env/cert-manager/platform-agnostic-multi-user\n</code></pre> Esto instala argo con el ejecutor emissary seguro para usar runasnonroot. Ten en cuenta que el instalador sigue siendo responsable de analizar los problemas de seguridad que surgen cuando los contenedores se ejecutan con acceso root y de decidir si los contenedores principales de los pipelines de kubeflow se ejecutan como runasnonroot. Se recomienda encarecidamente que los contenedores principales de los pipelines se instalen y ejecuten como runasnonroot y sin capacidades especiales para mitigar los riesgos de seguridad.</p>"},{"location":"guias/instalacion/#dependencias-del-multi-user-kubeflow-pipelines","title":"Dependencias del Multi-User Kubeflow Pipelines","text":"<ul> <li>Istio + Recursos de Istio para Kubeflow</li> <li>Roles de Kubeflow</li> <li>AuthService OIDC (o servicio de autenticaci\u00f3n espec\u00edfico del proveedor de la nube)</li> <li>Perfiles + KFAM</li> </ul> <p>Verificaci\u00f3n de instalaci\u00f3n correcta:</p> <pre><code>kubectl get pods -n kubeflow\n</code></pre>"},{"location":"guias/instalacion/#kserve","title":"KServe","text":"<p>KFServing fue renombrado a KServe.</p> <p>Instalar el componente KServe:</p> <pre><code>kubectl apply -k contrib/kserve/kserve\n</code></pre> <p>Instalar la aplicaci\u00f3n web de modelos:</p> <pre><code>kubectl apply -k contrib/kserve/models-web-app/overlays/kubeflow\n</code></pre> <p>Verificaci\u00f3n de instalaci\u00f3n correcta:</p> <pre><code>kubectl get pods -n kubeflow\n</code></pre>"},{"location":"guias/instalacion/#central-dashboard","title":"Central Dashboard","text":"<p>Instalar el componente oficial Central Dashboard de Kubeflow:</p> <pre><code>kubectl apply -k apps/centraldashboard/upstream/overlays/kserve\n</code></pre> <p>Verificaci\u00f3n de instalaci\u00f3n correcta:</p> <pre><code>kubectl get pods -n kubeflow\n</code></pre>"},{"location":"guias/instalacion/#admission-webhook","title":"Admission Webhook","text":"<p>Instalar el Admission Webhook para PodDefaults:</p> <pre><code>kubectl apply -k apps/admission-webhook/upstream/overlays/cert-manager\n</code></pre> <p>Verificaci\u00f3n de instalaci\u00f3n correcta:</p> <pre><code>kubectl get pods -n kubeflow\n</code></pre>"},{"location":"guias/instalacion/#notebooks","title":"Notebooks","text":"<p>Instalar el componente oficial Notebook Controller de Kubeflow:</p> <pre><code>kubectl apply -k apps/jupyter/notebook-controller/upstream/overlays/kubeflow\n</code></pre> <p>Instalar la aplicaci\u00f3n web Jupyter de Kubeflow:</p> <pre><code>kubectl apply -k apps/jupyter/jupyter-web-app/upstream/overlays/istio\n</code></pre> <p>Verificaci\u00f3n de instalaci\u00f3n correcta:</p> <pre><code>kubectl get pods -n kubeflow\n</code></pre>"},{"location":"guias/instalacion/#pvc-viewer-controller","title":"PVC Viewer Controller","text":"<p>Instalar el componente oficial PVC Viewer Controller de Kubeflow:</p> <pre><code>kubectl apply -k apps/pvcviewer-controller/upstream/default\n</code></pre> <p>Verificaci\u00f3n de instalaci\u00f3n correcta:</p> <pre><code>kubectl get pods -n kubeflow\n</code></pre>"},{"location":"guias/instalacion/#perfiles-kfam","title":"Perfiles + KFAM","text":"<p>Instalar el controlador de perfiles y el Kubeflow Access-Management (KFAM) como componentes oficiales de Kubeflow:</p> <pre><code>kubectl apply -k apps/profiles/upstream/overlays/kubeflow\n</code></pre>"},{"location":"guias/instalacion/#aplicacion-web-de-volumenes","title":"Aplicaci\u00f3n Web de Vol\u00famenes","text":"<p>Instalar la aplicaci\u00f3n web de vol\u00famenes como componente oficial de Kubeflow:</p> <pre><code>kubectl apply -k apps/volumes-web-app/upstream/overlays/istio\n</code></pre> <p>Verificaci\u00f3n de instalaci\u00f3n correcta:</p> <pre><code>kubectl get pods -n kubeflow\n</code></pre> <p>IMPORTANTE</p> <p>Se deben revisar los siguientes ficheros para asegurarse de que las URLs est\u00e1n correctamente configuradas antes de continuar con la instalaci\u00f3n:</p> <ul> <li>common/keycloak/base/config-map.yaml</li> <li>common/keycloak/base/deployment.yaml</li> <li>common/keycloak/overlays/istio/auth-certificates.yaml</li> <li>common/oidc-client/oidc-authservice/base/params.env</li> <li>common/oidc-client/oidc-authservice/base/statefulset.yaml</li> <li>ingress.yaml</li> </ul>"},{"location":"guias/instalacion/#ingress","title":"Ingress","text":"<p>Aplicar la configuraci\u00f3n de Ingress para el cl\u00faster de Kubeflow:</p> <pre><code>kubectl apply -f ingress.yaml\n</code></pre>"},{"location":"guias/instalacion/#keycloak","title":"Keycloak","text":"<p>Keycloak es un proveedor de identidad y acceso con soporte para OpenID Connect (OIDC) y SAML 2.0. En esta instalaci\u00f3n, Keycloak se configurar\u00e1 para gestionar la autenticaci\u00f3n y la autorizaci\u00f3n de los usuarios. Incluye m\u00faltiples opciones de backend de autenticaci\u00f3n y permite la configuraci\u00f3n de usuarios y roles seg\u00fan las necesidades espec\u00edficas del entorno. Para cualquier despliegue de Kubeflow en producci\u00f3n, es esencial configurar correctamente los usuarios y las pol\u00edticas de seguridad en Keycloak.</p> <p>Instalar Keycloak:</p> <p>Warning</p> <p>Para su correcta instalac\u00edon es necesario el uso de la herramienta <code>jq</code>. En caso de no tenerla instalada, ejecutar el siguiente comando:</p> <pre><code>sudo apt install jq\n</code></pre> <p>Una vez verificado que se tiene instalada dicha herramienta, se puede proceder con la instalaci\u00f3n:</p> <pre><code>kubectl apply -k common/keycloak/overlays/istio\nkubectl get secrets keycloak-cert -n auth -o json | jq 'del(.metadata[\"namespace\",\"creationTimestamp\",\"resourceVersion\",\"selfLink\",\"uid\",\"annotations\"])' | kubectl apply -n istio-system -f -\n</code></pre> <p>Una vez instalado correctamente <code>Keycloak</code> se deberan realizar una serie de ajuestes en la configuracion de la herramienta.</p> <p>Info</p> <p>Para acceder a la interfaz de <code>Keycloak</code> se utilizar\u00e1 la URL</p> <pre><code>https://keycloak-admin.ai.inesdata.upm/auth\n</code></pre> <p>para la cual ser\u00e1 necesario haber establecido un tunel SSH previamente.</p> <p>Warning</p> <p>Se deber\u00e1 crear el <code>Realm</code> que contiene la configurac\u00edon necesaria para que la plataforme se integre correctamente con <code>Keycloak</code>. Para ello se puede descargar desde  aqu\u00ed .</p> <p>Para crearlo pulsar en el desplegable de la esquina superior izquierda y hacer  click sobre <code>Create realm</code>.</p> <p></p> <p>En la pantalla que aparece, clickar sobre <code>Browse</code>, seleccionar el <code>Realm</code> descargado, ponerle un nombre, y hacer  click en <code>Create</code>.</p> <p></p> <p>Con el <code>Realm</code> en funcionamiento se deber\u00e1 a\u00f1adir la URL contenida en la variable <code>REDIRECT_URL</code> del fichero <code>common/oidc-client/oidc-authservice/base/params.env</code> en la secci\u00f3n <code>Valid redirect URIs</code> de la configuraci\u00f3n del cliente <code>kubeflow-oidc-authservice</code> tal y como se muestra en la siguiente imagen:</p> <p></p> <p>En esa misma ventana verificar tambi\u00e9n el par\u00e1metro <code>Front-channel logout URL</code> y asegurarse de que contiene la URL de acceso a la plataforma.</p> <p>Verificaci\u00f3n de instalaci\u00f3n correcta:</p> <pre><code>kubectl get pods -n auth\n</code></pre>"},{"location":"guias/instalacion/#authservice","title":"AuthService","text":"<p>El AuthService OIDC extiende las capacidades de tu Ingress-Gateway de Istio, para que pueda funcionar como un cliente OIDC:</p> <p>Warning</p> <p>Antes de proceder con la instalaci\u00f3n del AuthService, completar el parametro <code>CLIENT_SECRET</code> ubicado en <code>common/oidc-client/oidc-authservice/base/secret_params.env</code> con el valor que se encuentra en la UI de Keycloak en la secci\u00f3n Clients -&gt; kubeflow-oidc-authservice -&gt; Credentials -&gt; Client Secret.</p> <p>Una vez guardados los cambios se puede proseguir con la instalaci\u00f3n del OIDC AuthService.</p> <pre><code>kubectl apply -k common/oidc-client/oidc-authservice/base\n</code></pre> <p>Verificaci\u00f3n de instalaci\u00f3n correcta:</p> <pre><code>kubectl get pods -n istio-system\n</code></pre>"},{"location":"guias/instalacion/#namespace-del-usuario","title":"Namespace del Usuario","text":"<p>Se utilizar\u00e1 el script <code>kubeflow-admin.sh</code>.</p> <p>Info</p> <p>Tras seguir estos pasos y comprobar que se puede acceder correctamente a Keycloak al Dashboard de Kubeflow con las credenciales correspondientes, se puede dar por finalizada la instalacion de la plataforma.</p>"},{"location":"guias/usuario/","title":"Introducci\u00f3n a la plataforma","text":"<p>La plataforma de  desarrollo Inteligencia Artificial, <code>Inesdata-AI-Services</code> es una instancia customizada de kubeflow. El objetivo de esta gu\u00eda no es entrar en detalle sobre <code>kubeflow</code>, para ello remitimos al lector a la gu\u00eda oficial de <code>kubeflow</code> sino hacer una introducci\u00f3n a la misma, destacando los m\u00f3dulos principales.</p> <p>La plataforma de <code>Inesdata-AI-Services</code> cuenta con los siguientes componentes:</p> <ul> <li>Central Dashboard. Es el panel central de Kubeflow que proporciona una interfaz web autenticada para el resto de componentes (ver abajo)</li> <li>Kubeflow Notebooks. Proporciona una manera de ejecutar entorno de desarrollo web dentro del cl\u00faster de Kubernetes ejecut\u00e1ndolos en forma de <code>Pods</code>. Esta es el componente principal de <code>Inesdata-AI-Services</code>.</li> <li>Kubeflow Pipelines v2. Permite crear e implementar flujos (pipelines) escalables de Inteligencia Artificial usando contenedores <code>Docker</code></li> <li>KServe Permite a \"serverless\" inferencia y de alto rendimiento usnado para los frameworks de desarrollo m\u00e1s comunes de IA como TensorFlow, PyTorch, Scikit-learn, ONNX, etc.</li> </ul>"},{"location":"guias/usuario/#acceso-a-la-plataforma","title":"Acceso a la plataforma","text":"<p>A la plataforma se accede via web a trav\u00e9s de la siguiente direcci\u00f3n web:</p> <pre><code>https://kubeflow.ai.inesdata-project.eu/\n</code></pre> <p>Esta direcci\u00f3n te redirigir\u00e1 al proveedor de identidad implementado en <code>Inesdata-AI-Services</code> (<code>Keycloak</code>). Una vez autenticado, se redirigira al compomente <code>Central Dashboard</code>.</p>"},{"location":"guias/usuario/#componentes-de-la-plataforma","title":"Componentes de la plataforma","text":""},{"location":"guias/usuario/#central-dashboard","title":"Central Dashboard","text":"<p>Central Dashboard es el panel central de <code>Kubeflow</code> que proporciona una interfaz web autenticada para el resto de componentes. Este es el punto principal de entrada a la plataforma desde el cual puedes navegar al resto de componentes descritos en las siguientes secciones.</p> <p></p>"},{"location":"guias/usuario/#volumenes","title":"Vol\u00famenes","text":"<p>Los volumenes permiten el almacenamiento de datos. Este es un componente muy importante ya que permite la persistencia de datos, y a su vez ser\u00e1n los que se usen en el resto de servicios/componentes tales como los notebooks o pipelines. Adem\u00e1s, esta capacidad de persistencia permite que si los servicios de notebook se eliminan/paran, lo almacenado en estos vol\u00famenes puede ser reutilizado en otras instancias.</p> <p></p>"},{"location":"guias/usuario/#kubeflow-notebooks","title":"Kubeflow Notebooks","text":"<p>Kubeflow Notebooks. Proporciona una manera de ejecutar entorno de desarrollo web dentro del cl\u00faster de Kubernetes ejecut\u00e1ndolos en forma de <code>Pods</code>. Esta es el componente principal de <code>Inesdata-AI-Services</code>.</p> <p>Ver la secci\u00f3n ejemplos: Mi primer notebook, para ver un ejemplo detallado de c\u00f3mo crear un notebook</p> <p></p>"},{"location":"guias/usuario/#kubeflow-pipelines","title":"Kubeflow Pipelines","text":"<p>Kubeflow Pipelines es un componente que ermite crear e implementar flujos (pipelines) escalables de Inteligencia Artificial usando contenedores <code>Docker</code>. Los pipelines permiten orquestar m\u00faltiples pasos de un proceso de aprendizaje autom\u00e1tico, desde la preprocesamiento de datos hasta el entrenamiento y despliegue de modelos.</p> <p>Los usuarios pueden crear, implementar y supervisar pipelines de manera eficiente, lo que facilita la replicaci\u00f3n de resultados y la ejecuci\u00f3n de experimentos a mayor escala. Adem\u00e1s, Kubeflow Pipelines V2 ofrece mejoras en la gesti\u00f3n de metadatos y en la reutilizaci\u00f3n de componentes entre pipelines.</p> <p>En la secci\u00f3n ejemplos: Mi primer pipeline se ofrece un ejemplo detallado de c\u00f3mo crear y ejecutar un pipeline.</p> <p> </p>"},{"location":"guias/usuario/#kserve","title":"KServe","text":"<p>KServe permite una inferencia \"serverless\" y de alto rendimiento usando los frameworks de desarrollo m\u00e1s comunes de IA como TensorFlow, PyTorch, Scikit-learn, ONNX, entre otros. KServe facilita el despliegue de modelos en producci\u00f3n, proporcionando caracter\u00edsticas como autoescalado, gesti\u00f3n de versiones y monitorizaci\u00f3n.</p> <p>KServe integra capacidades avanzadas como la detecci\u00f3n de deriva de datos y la validaci\u00f3n de esquemas, asegurando que los modelos desplegados mantengan su rendimiento a lo largo del tiempo.</p> <p>Para m\u00e1s detalles sobre c\u00f3mo utilizar KServe, consulta la documentaci\u00f3n oficial: KServe Documentation.</p>"},{"location":"guias/usuario/examples/notebooks/","title":"Mi primer notebook","text":"<p>Vamos a ver el proceso de crear un notebook.:</p> <p></p> <ol> <li> <p>Desde el panel izquierdo de navegaci\u00f3n haz  click en la secci\u00f3n <code>Notebooks</code> .</p> </li> <li> <p>Haz  click en el bot\u00f3n <code>New</code> <code>Notebook</code> y rellena el siguiente formulario.</p> <ol> <li><code>Name</code> : Nombre del notebook.</li> <li><code>Notebook</code>: Selecciona qu\u00e9 tipo de notebook queremos utilizar. Las opciones son <code>jupyter</code>, <code>vscode</code> y <code>R</code></li> <li><code>Custom Notebook</code>: Selecciona la imagen docker para instanciar el notebook (1). </li> <li><code>CPU/RAM</code>. Indica qu\u00e9 capacidad de computo vas a utilizar.      </li> <li> <p><code>GPUs</code>. Indica si vas a necesitar GPU</p> <p>Warning</p> <p>Este asignaci\u00f3n, y la de <code>CPU/RAM</code> est\u00e1 limitada por los recursos asignados a la hora de crear el usuario. El total de <code>GPU/CPU/RAM</code> creados en los notebooks (o incluso <code>pipelines</code>) debe ser inferior a la cuota asignada.</p> </li> <li> <p><code>Workspace Volume</code>. Volumen que ser\u00e1 usado por el <code>Notebook</code> para persistir cualquier tipo de dato. </p> </li> <li> <p><code>Data Volumes</code>. Volumen adicional, independendiente, del <code>Workspace volume</code>. </p> </li> <li> <p><code>Advanced Options</code>.</p> <ol> <li><code>Configurations</code>. Indicar si desde el <code>Notebook</code> vas a querer crear o ejecutar <code>Pipeline</code>.</li> <li><code>Affinity/Tolerations</code>. Especifica las reglas de afinidad y tolerancia para la asignaci\u00f3n de recursos del notebook en el cl\u00faster de Kubernetes.<ul> <li><code>Affinity Config</code>: Permite definir reglas de afinidad para que el notebook se asigne a nodos espec\u00edficos que cumplan ciertos criterios.</li> <li><code>Tolerations Group</code>: Permite definir las tolerancias que el notebook tendr\u00e1 hacia ciertos taints aplicados en los nodos. Esto es \u00fatil para garantizar que los notebooks se ejecuten en nodos preparados para cargas espec\u00edficas, como aquellos con GPU.</li> </ul> </li> <li><code>Miscellaneous Settings</code>. Ajustes miscel\u00e1neos adicionales para el <code>Notebook</code>.<ul> <li><code>Enable Shared Memory</code>: Habilita la memoria compartida, lo cual es \u00fatil para ciertas aplicaciones que requieren segmentos de memoria compartida para la comunicaci\u00f3n entre procesos.</li> </ul> </li> </ol> </li> <li> <p>Haz  click en el bot\u00f3n <code>Launch</code></p> </li> </ol> </li> <li> <p> En la propia documentaci\u00f3n de <code>Kubeflow</code> se encuentra la lista de imagenes y la diferencia entre ellas: </p> </li> </ol> <p>Si todo hay ido correctamente, el <code>Notebook</code> aparecer\u00e1 en la lista  </p>"},{"location":"guias/usuario/examples/pipeline/","title":"Mi primer pipeline","text":"<p>Este ejempo sirve para ilustrar un pipeline de <code>kubeflow</code> usando <code>MNIST</code> dataset.</p> <p>El <code>pipeline</code> lo vamos a construir  usando  Lightweight Python Components</p> In\u00a0[361]: Copied! <pre>PIPELINE_NAME = \"MNIST\"\nPIPELINE_DESCRIPTION = \"Ejemplo de pipeline\"\nPIPELINE_VERSION = \"V1\"\n\nEXPERIMENT_NAME = PIPELINE_NAME + \"_\" + \"Best-accuracy\"\n</pre> PIPELINE_NAME = \"MNIST\" PIPELINE_DESCRIPTION = \"Ejemplo de pipeline\" PIPELINE_VERSION = \"V1\"  EXPERIMENT_NAME = PIPELINE_NAME + \"_\" + \"Best-accuracy\" <p>Cada paso en un pipeline se define via un <code>componente</code>, en este caso vamos a hacer un pipeline sencillo:</p> <ul> <li><code>download_data</code> -&gt; <code>train_data</code> -&gt; <code>test_data</code></li> </ul> In\u00a0[327]: Copied! <pre>import kfp\nfrom kfp import dsl, compiler\nfrom kfp.dsl import *\nfrom typing import *\nfrom kfp_server_api.exceptions import ApiException\n</pre> import kfp from kfp import dsl, compiler from kfp.dsl import * from typing import * from kfp_server_api.exceptions import ApiException In\u00a0[321]: Copied! <pre>@dsl.component(base_image=\"python:3.10\")\ndef download_data(test_dataset_path: Output[Dataset], \n                    train_dataset_path: Output[Dataset], \n                    metrics: Output[Metrics]):\n    \"\"\"Descarga los datos de train y test y las rutas donde se guardan estos datasets/artefactos, se envian el siguiente paso.\"\"\"\n\n    ## Install packages\n    import subprocess\n    import sys\n\n    def install(package):\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package,\n                                \"--extra-index-url=https://download.pytorch.org/whl/cpu\",\n                                \"--trusted-host=download.pytorch.org\"])\n\n    install(\"torch==2.0.0+cpu\")\n    install(\"torchvision==0.15.1+cpu\")\n    #install(\"matplotlib\")    \n\n\n    ## Libraries\n    import torch\n\n    from torchvision.transforms import transforms\n    from torchvision.datasets import MNIST\n\n    ## Download MNIST DATASET\n\n    transform=transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.1307,), (0.3081,))\n        ])\n\n    mnist_train  = MNIST(\".\", download=True, train=True, transform=transform)\n    mnist_test   = MNIST(\".\", download=True, train=False, transform=transform)\n\n    with open(train_dataset_path.path, \"wb\") as f:\n        torch.save(mnist_train,f)\n\n    with open(test_dataset_path.path, \"wb\") as f:\n        torch.save(mnist_test,f)\n\n    # metricas\n    metrics.log_metric(\"# Samples train dataset\", len(mnist_train))\n    metrics.log_metric(\"# Samples test dataset\",  len(mnist_test))\n</pre> @dsl.component(base_image=\"python:3.10\") def download_data(test_dataset_path: Output[Dataset],                      train_dataset_path: Output[Dataset],                      metrics: Output[Metrics]):     \"\"\"Descarga los datos de train y test y las rutas donde se guardan estos datasets/artefactos, se envian el siguiente paso.\"\"\"      ## Install packages     import subprocess     import sys      def install(package):         subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package,                                 \"--extra-index-url=https://download.pytorch.org/whl/cpu\",                                 \"--trusted-host=download.pytorch.org\"])      install(\"torch==2.0.0+cpu\")     install(\"torchvision==0.15.1+cpu\")     #install(\"matplotlib\")           ## Libraries     import torch      from torchvision.transforms import transforms     from torchvision.datasets import MNIST      ## Download MNIST DATASET      transform=transforms.Compose([         transforms.ToTensor(),         transforms.Normalize((0.1307,), (0.3081,))         ])      mnist_train  = MNIST(\".\", download=True, train=True, transform=transform)     mnist_test   = MNIST(\".\", download=True, train=False, transform=transform)      with open(train_dataset_path.path, \"wb\") as f:         torch.save(mnist_train,f)      with open(test_dataset_path.path, \"wb\") as f:         torch.save(mnist_test,f)      # metricas     metrics.log_metric(\"# Samples train dataset\", len(mnist_train))     metrics.log_metric(\"# Samples test dataset\",  len(mnist_test)) In\u00a0[322]: Copied! <pre>@dsl.component(base_image=\"python:3.10\")\ndef train(train_dataset_path: Input[Dataset], \n            model_path: Output[Model], \n            model_params: Output[Markdown],\n            batch_size: int, \n            epochs: int,\n            lr: float=0.1, \n            gamma: float=0.7,\n            ):\n    \"\"\"Entrenamos un model usando pytorch. La ruta donde se guarda el modelo/artefacto se envia al guiente paso\"\"\"\n\n    ## Install packages\n    import subprocess\n    import sys\n\n    def install(package):\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package,\n                                \"--extra-index-url=https://download.pytorch.org/whl/cpu\",\n                                \"--trusted-host=download.pytorch.org\"])\n\n    install(\"torch==2.0.0+cpu\")\n    install(\"torchvision==0.15.1+cpu\")\n    install(\"numba==0.56.4\")\n    install(\"numpy==1.23.5\")\n\n\n\n    ## Libraries\n\n    import torch\n    import torch.nn as nn\n    import torch.nn.functional as F\n    import torch.optim as optim\n    from torchvision import datasets, transforms\n    from torch.optim.lr_scheduler import StepLR\n\n\n    ## Read dataset\n    mnist_train = torch.load(train_dataset_path.path)\n\n    ## Net definition\n    class Net(nn.Module):\n        def __init__(self):\n            super(Net, self).__init__()\n            self.conv1 = nn.Conv2d(1, 32, 3, 1)\n            self.conv2 = nn.Conv2d(32, 64, 3, 1)\n            self.dropout1 = nn.Dropout(0.25)\n            self.dropout2 = nn.Dropout(0.5)\n            self.fc1 = nn.Linear(9216, 128)\n            self.fc2 = nn.Linear(128, 10)\n\n        def forward(self, x):\n            x = self.conv1(x)\n            x = F.relu(x)\n            x = self.conv2(x)\n            x = F.relu(x)\n            x = F.max_pool2d(x, 2)\n            x = self.dropout1(x)\n            x = torch.flatten(x, 1)\n            x = self.fc1(x)\n            x = F.relu(x)\n            x = self.dropout2(x)\n            x = self.fc2(x)\n            output = F.log_softmax(x, dim=1)\n            return output\n\n\n    # Training           \n    train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size)\n    model = Net().to(\"cpu\")\n    optimizer = optim.Adadelta(model.parameters(), lr=lr)\n    scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n\n\n\n    def _train(model, train_loader, optimizer, epoch):\n        model.train()\n        for batch_idx, (data, target) in enumerate(train_loader):\n            data, target = data.to(\"cpu\"), target.to(\"cpu\")\n            optimizer.zero_grad()\n            output = model(data)\n            loss = F.nll_loss(output, target)\n            loss.backward()\n            optimizer.step()\n            if batch_idx % 100 == 0:\n                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                    epoch, batch_idx * len(data), len(train_loader.dataset),\n                    100. * batch_idx / len(train_loader), loss.item()))\n\n    for epoch in range(1, epochs+1):\n        _train(model=model, train_loader = train_loader, optimizer=optimizer, epoch=epoch)\n        scheduler.step()\n\n    with open(model_path.path, \"wb\") as f:\n        torch.save(model.state_dict(),f)\n\n    markdown_content = '# MNIST Model \\n\\n '\n    markdown_content+= '## Model state dict: \\n'\n\n    for param_tensor in model.state_dict():\n        markdown_content+= \"\\t\" + str(model.state_dict()[param_tensor].size()) + \"\\n\"\n\n    with open(model_params.path, 'w') as f:\n        f.write(markdown_content)\n</pre> @dsl.component(base_image=\"python:3.10\") def train(train_dataset_path: Input[Dataset],              model_path: Output[Model],              model_params: Output[Markdown],             batch_size: int,              epochs: int,             lr: float=0.1,              gamma: float=0.7,             ):     \"\"\"Entrenamos un model usando pytorch. La ruta donde se guarda el modelo/artefacto se envia al guiente paso\"\"\"      ## Install packages     import subprocess     import sys      def install(package):         subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package,                                 \"--extra-index-url=https://download.pytorch.org/whl/cpu\",                                 \"--trusted-host=download.pytorch.org\"])      install(\"torch==2.0.0+cpu\")     install(\"torchvision==0.15.1+cpu\")     install(\"numba==0.56.4\")     install(\"numpy==1.23.5\")        ## Libraries      import torch     import torch.nn as nn     import torch.nn.functional as F     import torch.optim as optim     from torchvision import datasets, transforms     from torch.optim.lr_scheduler import StepLR       ## Read dataset     mnist_train = torch.load(train_dataset_path.path)      ## Net definition     class Net(nn.Module):         def __init__(self):             super(Net, self).__init__()             self.conv1 = nn.Conv2d(1, 32, 3, 1)             self.conv2 = nn.Conv2d(32, 64, 3, 1)             self.dropout1 = nn.Dropout(0.25)             self.dropout2 = nn.Dropout(0.5)             self.fc1 = nn.Linear(9216, 128)             self.fc2 = nn.Linear(128, 10)          def forward(self, x):             x = self.conv1(x)             x = F.relu(x)             x = self.conv2(x)             x = F.relu(x)             x = F.max_pool2d(x, 2)             x = self.dropout1(x)             x = torch.flatten(x, 1)             x = self.fc1(x)             x = F.relu(x)             x = self.dropout2(x)             x = self.fc2(x)             output = F.log_softmax(x, dim=1)             return output       # Training                train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size)     model = Net().to(\"cpu\")     optimizer = optim.Adadelta(model.parameters(), lr=lr)     scheduler = StepLR(optimizer, step_size=1, gamma=gamma)        def _train(model, train_loader, optimizer, epoch):         model.train()         for batch_idx, (data, target) in enumerate(train_loader):             data, target = data.to(\"cpu\"), target.to(\"cpu\")             optimizer.zero_grad()             output = model(data)             loss = F.nll_loss(output, target)             loss.backward()             optimizer.step()             if batch_idx % 100 == 0:                 print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(                     epoch, batch_idx * len(data), len(train_loader.dataset),                     100. * batch_idx / len(train_loader), loss.item()))      for epoch in range(1, epochs+1):         _train(model=model, train_loader = train_loader, optimizer=optimizer, epoch=epoch)         scheduler.step()      with open(model_path.path, \"wb\") as f:         torch.save(model.state_dict(),f)      markdown_content = '# MNIST Model \\n\\n '     markdown_content+= '## Model state dict: \\n'      for param_tensor in model.state_dict():         markdown_content+= \"\\t\" + str(model.state_dict()[param_tensor].size()) + \"\\n\"      with open(model_params.path, 'w') as f:         f.write(markdown_content) In\u00a0[323]: Copied! <pre>@dsl.component(packages_to_install=['scikit-learn'], base_image=\"python:3.10\")\ndef test(test_dataset_path: Input[Dataset], \n            model_path: Input[Model],\n            cm: Output[ClassificationMetrics],\n            acc: Output[Metrics]):\n\n    from typing import Tuple, List\n\n    ## Install packages\n    import subprocess\n    import sys\n\n    def install(package):\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package,\n                                \"--extra-index-url=https://download.pytorch.org/whl/cpu\",\n                                \"--trusted-host=download.pytorch.org\"])\n\n    install(\"torch==2.0.0+cpu\")\n    install(\"torchvision==0.15.1+cpu\")\n    install(\"numba==0.56.4\")\n    install(\"numpy==1.23.5\")\n\n    import torch\n    import torch.nn as nn\n    import torch.nn.functional as F\n\n\n\n    ## Net definition\n    class Net(nn.Module):\n        def __init__(self):\n            super(Net, self).__init__()\n            self.conv1 = nn.Conv2d(1, 32, 3, 1)\n            self.conv2 = nn.Conv2d(32, 64, 3, 1)\n            self.dropout1 = nn.Dropout(0.25)\n            self.dropout2 = nn.Dropout(0.5)\n            self.fc1 = nn.Linear(9216, 128)\n            self.fc2 = nn.Linear(128, 10)\n\n        def forward(self, x):\n            x = self.conv1(x)\n            x = F.relu(x)\n            x = self.conv2(x)\n            x = F.relu(x)\n            x = F.max_pool2d(x, 2)\n            x = self.dropout1(x)\n            x = torch.flatten(x, 1)\n            x = self.fc1(x)\n            x = F.relu(x)\n            x = self.dropout2(x)\n            x = self.fc2(x)\n            output = F.log_softmax(x, dim=1)\n            return output\n\n    model = Net()\n    model.load_state_dict(torch.load(model_path.path))\n    model.eval()\n\n    mnist_test = torch.load(test_dataset_path.path)\n    test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=32)\n\n\n\n    def _test(model, test_loader) -&gt; Tuple[List, List, float, float]:\n\n        y_pred = []\n        y_true = []\n\n        model.eval()\n        test_loss = 0\n        correct = 0\n        with torch.no_grad():\n            for data, target in test_loader:\n                data, target = data.to(\"cpu\"), target.to(\"cpu\")\n\n\n\n                output = model(data)\n                test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n                pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n                correct += pred.eq(target.view_as(pred)).sum().item()\n\n                y_true.extend(target.numpy())\n                y_pred.extend(pred.numpy())\n\n        test_loss /= len(test_loader.dataset)\n        accuracy = 100. * correct / len(test_loader.dataset)\n        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n            test_loss, correct, len(test_loader.dataset), accuracy))\n\n        return y_true, y_pred, test_loss, accuracy\n\n    y_true, y_pred, test_loss, accuracy = _test(model=model, test_loader=test_loader)\n\n    from sklearn.metrics import confusion_matrix\n\n\n    # confusion matrix\n    cm.log_confusion_matrix(\n        [str(i) for i in range(10)],\n        confusion_matrix(y_true, y_pred).tolist() # .tolist() to convert np array to list.\n    )\n\n    acc.log_metric(\"avg_loss\",test_loss)\n    acc.log_metric(\"accuracy\",accuracy)\n</pre> @dsl.component(packages_to_install=['scikit-learn'], base_image=\"python:3.10\") def test(test_dataset_path: Input[Dataset],              model_path: Input[Model],             cm: Output[ClassificationMetrics],             acc: Output[Metrics]):      from typing import Tuple, List      ## Install packages     import subprocess     import sys      def install(package):         subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package,                                 \"--extra-index-url=https://download.pytorch.org/whl/cpu\",                                 \"--trusted-host=download.pytorch.org\"])      install(\"torch==2.0.0+cpu\")     install(\"torchvision==0.15.1+cpu\")     install(\"numba==0.56.4\")     install(\"numpy==1.23.5\")      import torch     import torch.nn as nn     import torch.nn.functional as F        ## Net definition     class Net(nn.Module):         def __init__(self):             super(Net, self).__init__()             self.conv1 = nn.Conv2d(1, 32, 3, 1)             self.conv2 = nn.Conv2d(32, 64, 3, 1)             self.dropout1 = nn.Dropout(0.25)             self.dropout2 = nn.Dropout(0.5)             self.fc1 = nn.Linear(9216, 128)             self.fc2 = nn.Linear(128, 10)          def forward(self, x):             x = self.conv1(x)             x = F.relu(x)             x = self.conv2(x)             x = F.relu(x)             x = F.max_pool2d(x, 2)             x = self.dropout1(x)             x = torch.flatten(x, 1)             x = self.fc1(x)             x = F.relu(x)             x = self.dropout2(x)             x = self.fc2(x)             output = F.log_softmax(x, dim=1)             return output      model = Net()     model.load_state_dict(torch.load(model_path.path))     model.eval()      mnist_test = torch.load(test_dataset_path.path)     test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=32)        def _test(model, test_loader) -&gt; Tuple[List, List, float, float]:          y_pred = []         y_true = []          model.eval()         test_loss = 0         correct = 0         with torch.no_grad():             for data, target in test_loader:                 data, target = data.to(\"cpu\"), target.to(\"cpu\")                    output = model(data)                 test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss                 pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability                 correct += pred.eq(target.view_as(pred)).sum().item()                  y_true.extend(target.numpy())                 y_pred.extend(pred.numpy())          test_loss /= len(test_loader.dataset)         accuracy = 100. * correct / len(test_loader.dataset)         print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(             test_loss, correct, len(test_loader.dataset), accuracy))          return y_true, y_pred, test_loss, accuracy      y_true, y_pred, test_loss, accuracy = _test(model=model, test_loader=test_loader)      from sklearn.metrics import confusion_matrix       # confusion matrix     cm.log_confusion_matrix(         [str(i) for i in range(10)],         confusion_matrix(y_true, y_pred).tolist() # .tolist() to convert np array to list.     )      acc.log_metric(\"avg_loss\",test_loss)     acc.log_metric(\"accuracy\",accuracy) In\u00a0[324]: Copied! <pre># Definimos el pipeline\n@dsl.pipeline(\n    name='MNIST',\n    description='Ejemplo de pipeline de entrenamiento',\n)\ndef run(batch_size:int=32, epochs:int=2):\n    step_1 = download_data()\n    step_2 = train(train_dataset_path=step_1.outputs[\"train_dataset_path\"], batch_size=batch_size, epochs=epochs)\n    step_3 = test(test_dataset_path=step_1.outputs[\"test_dataset_path\"], model_path=step_2.outputs[\"model_path\"] )\n</pre> # Definimos el pipeline @dsl.pipeline(     name='MNIST',     description='Ejemplo de pipeline de entrenamiento', ) def run(batch_size:int=32, epochs:int=2):     step_1 = download_data()     step_2 = train(train_dataset_path=step_1.outputs[\"train_dataset_path\"], batch_size=batch_size, epochs=epochs)     step_3 = test(test_dataset_path=step_1.outputs[\"test_dataset_path\"], model_path=step_2.outputs[\"model_path\"] ) In\u00a0[287]: Copied! <pre># Compilamos el pipeline\ncompiler.Compiler().compile(run, package_path='pipeline.yaml')\n</pre> # Compilamos el pipeline compiler.Compiler().compile(run, package_path='pipeline.yaml') <p>A continuaci\u00f3n registramos el pipeline</p> In\u00a0[\u00a0]: Copied! <pre>client = kfp.Client()\nnamespace = client.get_user_namespace()\n</pre> client = kfp.Client() namespace = client.get_user_namespace() In\u00a0[\u00a0]: Copied! <pre>try:\n    pipeline = client.upload_pipeline(pipeline_package_path=\"pipeline.yaml\", \n                                      pipeline_name=PIPELINE_NAME, \n                                      description=PIPELINE_DESCRIPTION, \n                                      namespace=namespace)\nexcept ApiException as e:\n    if \"Already exist\" in e.body:\n        print(\"Pipeline {} already exists.\".format(PIPELINE_NAME))\n</pre> try:     pipeline = client.upload_pipeline(pipeline_package_path=\"pipeline.yaml\",                                        pipeline_name=PIPELINE_NAME,                                        description=PIPELINE_DESCRIPTION,                                        namespace=namespace) except ApiException as e:     if \"Already exist\" in e.body:         print(\"Pipeline {} already exists.\".format(PIPELINE_NAME))      <p>Los pipelines se pueden agrupar y versionar</p> In\u00a0[\u00a0]: Copied! <pre>try:\n    pipeline_version = client.upload_pipeline_version(\n        pipeline_package_path=\"pipeline.yaml\",\n        pipeline_version_name=PIPELINE_VERSION,\n        pipeline_id=pipeline.pipeline_id,\n        description=\"Primera version\"\n    )\nexcept ApiException as e:\n    if \"Already exist\" in e.body:\n        print(\"Pipeline {} with version {} already exists.\".format(pipeline.display_name, PIPELINE_VERSION))\n</pre> try:     pipeline_version = client.upload_pipeline_version(         pipeline_package_path=\"pipeline.yaml\",         pipeline_version_name=PIPELINE_VERSION,         pipeline_id=pipeline.pipeline_id,         description=\"Primera version\"     ) except ApiException as e:     if \"Already exist\" in e.body:         print(\"Pipeline {} with version {} already exists.\".format(pipeline.display_name, PIPELINE_VERSION)) <p>Como vamos a hacer varias ejecuciones, estas se pueden agrupar por experimentos</p> In\u00a0[\u00a0]: Copied! <pre>try:\n    experiment = client.get_experiment(experiment_name=EXPERIMENT_NAME)\nexcept:\n    experiment = client.create_experiment(EXPERIMENT_NAME)\n</pre> try:     experiment = client.get_experiment(experiment_name=EXPERIMENT_NAME) except:     experiment = client.create_experiment(EXPERIMENT_NAME) In\u00a0[313]: Copied! <pre>import time\n</pre> import time In\u00a0[\u00a0]: Copied! <pre>params = {\"batch_size\": 32, \"epochs\": 1}\nrun_pipeline = client.run_pipeline(experiment_id=experiment.experiment_id,\n                    job_name=pipeline.display_name + \"_run_\" + time.strftime(\"%Y-%m-%d--%H:%M:%S\", time.gmtime()),\n                    params=params,\n                    pipeline_id=pipeline_version.pipeline_id,\n                    version_id=pipeline_version.pipeline_version_id)\n</pre> params = {\"batch_size\": 32, \"epochs\": 1} run_pipeline = client.run_pipeline(experiment_id=experiment.experiment_id,                     job_name=pipeline.display_name + \"_run_\" + time.strftime(\"%Y-%m-%d--%H:%M:%S\", time.gmtime()),                     params=params,                     pipeline_id=pipeline_version.pipeline_id,                     version_id=pipeline_version.pipeline_version_id) In\u00a0[\u00a0]: Copied! <pre># Vamos a hacer otra ejecuci\u00f3n con otros par\u00e1metros\nparams = {\"batch_size\": 64, \"epochs\": 5}\nrun_pipeline = client.run_pipeline(experiment_id=experiment.experiment_id,\n                    job_name=pipeline.display_name + \"_run_\" + time.strftime(\"%Y-%m-%d--%H:%M:%S\", time.gmtime()),\n                    params=params,\n                    pipeline_id=pipeline_version.pipeline_id,\n                    version_id=pipeline_version.pipeline_version_id)\n</pre> # Vamos a hacer otra ejecuci\u00f3n con otros par\u00e1metros params = {\"batch_size\": 64, \"epochs\": 5} run_pipeline = client.run_pipeline(experiment_id=experiment.experiment_id,                     job_name=pipeline.display_name + \"_run_\" + time.strftime(\"%Y-%m-%d--%H:%M:%S\", time.gmtime()),                     params=params,                     pipeline_id=pipeline_version.pipeline_id,                     version_id=pipeline_version.pipeline_version_id)"},{"location":"guias/usuario/examples/pipeline/#mi-primer-pipeline","title":"Mi primer pipeline\u00b6","text":""},{"location":"guias/usuario/examples/pipeline/#kubeflow-pipelines-mnist-benchmark","title":"Kubeflow pipelines: MNIST benchmark\u00b6","text":""},{"location":"guias/usuario/examples/pipeline/#constantes","title":"Constantes\u00b6","text":"<p>Vamos a definir algunas constantes que ser\u00e1n usadas m\u00e1s adelante</p>"},{"location":"guias/usuario/examples/pipeline/#componentes","title":"Componentes\u00b6","text":""},{"location":"guias/usuario/examples/pipeline/#download-data","title":"Download data\u00b6","text":"<p>Descargamos el conjunto de train y test</p>"},{"location":"guias/usuario/examples/pipeline/#entrenamos-el-modelo","title":"Entrenamos el modelo\u00b6","text":""},{"location":"guias/usuario/examples/pipeline/#evaluamos-el-modelo","title":"Evaluamos el modelo\u00b6","text":""},{"location":"guias/usuario/examples/pipeline/#pipeline","title":"Pipeline\u00b6","text":""},{"location":"guias/usuario/examples/pipeline/#definicion","title":"Definici\u00f3n\u00b6","text":"<p>A continuaci\u00f3n vamos a:</p> <ol> <li>Definir el pipeline</li> <li>Compilarlo</li> <li>Registrar</li> </ol>"},{"location":"guias/usuario/examples/pipeline/#ejecucion","title":"Ejecucion\u00b6","text":""},{"location":"guias/usuario/examples/volumen/","title":"Mi primer volumen","text":"<p>Vamos a ver el proceso de crear un volumen:</p> <p></p> <ol> <li>Desde el panel izquierdo de navegaci\u00f3n haz  click en la secci\u00f3n <code>Volumes</code> .</li> <li> <p>Haz  click en el bot\u00f3n <code>New volume</code> y rellena el siguiente formulario.</p> <ol> <li><code>Name</code>: Nombre del volumen.</li> <li> <p><code>Volume size in Gi</code>: Tama\u00f1o del volumen.</p> <p>Note</p> <p>Este tama\u00f1o est\u00e1 limitado por los recursos asignados a la hora de crear el usuario. El total de volumenes creados debe ser inferior a la cuota asignada.</p> </li> <li> <p><code>Storage Class</code>: Usa el valor por defecto <code>csi-ceph-sc</code></p> </li> <li><code>Access mode</code>: Selecciona el acceso que aplique. (1)</li> <li>Haz  click en <code>create</code>.</li> </ol> </li> <li> <p> Ver la documentaci\u00f3n oficial de <code>Kubernetes</code> para entende la diferencia entre los access-modes</p> </li> </ol> <p>Si todo hay ido correctamente, el volumen aparecer\u00e1 en la lista </p>"}]}